{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "huHqTHG7ycD0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12252,
     "status": "ok",
     "timestamp": 1701390717408,
     "user": {
      "displayName": "Aishwarya Agrawal",
      "userId": "02157546517471328250"
     },
     "user_tz": 300
    },
    "id": "huHqTHG7ycD0",
    "outputId": "1008d2e2-c6d7-42df-e3fe-8394f4620ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.9.10-py3-none-any.whl (917 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.6/917.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.6)\n",
      "Collecting aiostream<0.6.0,>=0.5.2 (from llama-index)\n",
      "  Downloading aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from llama-index)\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
      "Collecting httpx (from llama-index)\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
      "Collecting openai>=1.1.0 (from llama-index)\n",
      "  Downloading openai-1.3.6-py3-none-any.whl (220 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index)\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.10.13)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.3.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx->llama-index)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.4)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=1.1.0->llama-index) (1.1.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
      "Installing collected packages: mypy-extensions, marshmallow, h11, deprecated, beautifulsoup4, aiostream, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.2\n",
      "    Uninstalling beautifulsoup4-4.11.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiostream-0.5.2 beautifulsoup4-4.12.2 dataclasses-json-0.6.3 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 llama-index-0.9.10 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.6 tiktoken-0.5.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106b87a",
   "metadata": {
    "id": "a106b87a"
   },
   "outputs": [],
   "source": [
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70ed38",
   "metadata": {
    "id": "af70ed38"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "openai_api_key=\"API_KEY\"\n",
    "llm = ChatOpenAI(openai_api_key=\"OPENAI_API_KEY\")\n",
    "\n",
    "# chat(\n",
    "#     [\n",
    "#         HumanMessage(\n",
    "#             content=\"Give me a specific activity suggestion based on my passion of programming. Your response length is one sentence maximum.\"\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c483fe1",
   "metadata": {
    "id": "3c483fe1"
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca36bf0",
   "metadata": {
    "id": "2ca36bf0"
   },
   "outputs": [],
   "source": [
    "####\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_path='/Users/danielhoskins/src/llms/llms_project_GrocerEase/grocery.csv', source_column=\"Description\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556329e",
   "metadata": {
    "id": "5556329e"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings(openai_api_key=openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51245357",
   "metadata": {
    "id": "51245357"
   },
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=2000, memory_key=\"chat_history\", return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b3ee9",
   "metadata": {
    "id": "c11b3ee9"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570d4c0",
   "metadata": {
    "id": "b570d4c0"
   },
   "outputs": [],
   "source": [
    "# NEw code\n",
    "# from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "qa_system_template = \"\"\"You are a helpful AI assistant focused solely on recommending grocery items to online shoppers. Your function is to suggest food and related consumables that can be found in a grocery store. No matter the context or the nature of the user's question, your responses should always involve grocery item recommendations. If a user inquires about needs for a specific situation or event, you will only recommend grocery items that are suitable for that context.\n",
    "# ----------------\n",
    "# {context}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(qa_system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "qa_system_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory, condense_question_prompt=qa_system_prompt,\n",
    "                                            verbose=True, combine_docs_chain_kwargs={\"prompt\": qa_system_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a720b",
   "metadata": {
    "id": "b81a720b",
    "outputId": "585048b0-7c27-49ea-83ce-d81ca5b03d01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI assistant focused solely on recommending grocery items to online shoppers. Your function is to suggest food and related consumables that can be found in a grocery store. No matter the context or the nature of the user's question, your responses should always involve grocery item recommendations. If a user inquires about needs for a specific situation or event, you will only recommend grocery items that are suitable for that context. \n",
      "# ----------------\n",
      "# ﻿SKU: Nature Valley granola bars\n",
      "Type: Snacks\n",
      "Cost: $2.99\n",
      "Quantity (g): 170\n",
      "Description: Oat-based snack bars\n",
      "\n",
      "﻿SKU: Triscuits\n",
      "Type: Snacks\n",
      "Cost: $3.49\n",
      "Quantity (g): 170\n",
      "Description: Wheat cracker snacks\n",
      "\n",
      "﻿SKU: Oreos\n",
      "Type: Snacks\n",
      "Cost: $3.49\n",
      "Quantity (g): 170\n",
      "Description: Chocolate sandwich cookies\n",
      "\n",
      "﻿SKU: Skippy peanut butter\n",
      "Type: Spreads\n",
      "Cost: $3.29\n",
      "Quantity (g): 700\n",
      "Description: Creamy or chunky spread\n",
      "Human: I'm going on a 3-day backpacking trip through the smokey mountains. What will I need?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"I'm going on a 3-day backpacking trip through the smokey mountains. What will I need?\",\n",
       " 'chat_history': [HumanMessage(content=\"I'm going on a 3-day backpacking trip through the smokey mountains. What will I need?\"),\n",
       "  AIMessage(content=\"For your 3-day backpacking trip through the Smoky Mountains, here are some grocery items you might find useful:\\n\\n1. Nature Valley granola bars: These oat-based snack bars are convenient and provide energy for your hikes.\\n2. Triscuits: These wheat cracker snacks can be a great source of carbohydrates and are easy to pack.\\n3. Skippy peanut butter: A jar of Skippy peanut butter can be a versatile spread for sandwiches or as a source of protein and healthy fats.\\n4. Bottled water: Staying hydrated is crucial during outdoor activities, so make sure to bring enough water for your trip.\\n5. Dried fruit and nuts: These lightweight and nutritious snacks can provide you with a quick energy boost.\\n6. Instant oatmeal: Easy to prepare and a great source of energy for breakfasts on the go.\\n7. Jerky or canned tuna: These protein-rich options can be a good addition to your meals.\\n8. Trail mix: A mix of nuts, dried fruit, and chocolate can be a tasty and energy-dense snack for the trail.\\n9. Energy gels or bars: These compact and high-energy snacks can be useful during long hikes or when you need a quick boost.\\n\\nRemember to check the regulations of the area you'll be hiking through for any restrictions on food storage or waste disposal. Enjoy your backpacking trip!\")],\n",
       " 'answer': \"For your 3-day backpacking trip through the Smoky Mountains, here are some grocery items you might find useful:\\n\\n1. Nature Valley granola bars: These oat-based snack bars are convenient and provide energy for your hikes.\\n2. Triscuits: These wheat cracker snacks can be a great source of carbohydrates and are easy to pack.\\n3. Skippy peanut butter: A jar of Skippy peanut butter can be a versatile spread for sandwiches or as a source of protein and healthy fats.\\n4. Bottled water: Staying hydrated is crucial during outdoor activities, so make sure to bring enough water for your trip.\\n5. Dried fruit and nuts: These lightweight and nutritious snacks can provide you with a quick energy boost.\\n6. Instant oatmeal: Easy to prepare and a great source of energy for breakfasts on the go.\\n7. Jerky or canned tuna: These protein-rich options can be a good addition to your meals.\\n8. Trail mix: A mix of nuts, dried fruit, and chocolate can be a tasty and energy-dense snack for the trail.\\n9. Energy gels or bars: These compact and high-energy snacks can be useful during long hikes or when you need a quick boost.\\n\\nRemember to check the regulations of the area you'll be hiking through for any restrictions on food storage or waste disposal. Enjoy your backpacking trip!\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"question\": \"I'm going on a 3-day backpacking trip through the smokey mountains. What will I need?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87f665",
   "metadata": {
    "id": "2c87f665",
    "outputId": "240bd891-46c1-4308-eab1-5b0e5f38ce75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI assistant focused solely on recommending grocery items to online shoppers. Your function is to suggest food and related consumables that can be found in a grocery store. No matter the context or the nature of the user's question, your responses should always involve grocery item recommendations. If a user inquires about needs for a specific situation or event, you will only recommend grocery items that are suitable for that context. \n",
      "# ----------------\n",
      "# ﻿SKU: Spooky Cookies\n",
      "Type: Snacks\n",
      "Cost: 4.99\n",
      "Quantity (g): 12\n",
      "Description: Halloween themed cookies\n",
      "\n",
      "﻿SKU: Haunted chips\n",
      "Type: Snacks\n",
      "Cost: $5.99\n",
      "Quantity (g): 6\n",
      "Description: Scary and festive treats perfect for the fall season\n",
      "\n",
      "﻿SKU: Keebler cookies\n",
      "Type: Snacks\n",
      "Cost: $2.99\n",
      "Quantity (g): 170\n",
      "Description: Assorted cookies\n",
      "\n",
      "﻿SKU: Chips Ahoy cookies\n",
      "Type: Snacks\n",
      "Cost: $2.99\n",
      "Quantity (g): 170\n",
      "Description: Chocolate chip cookies\n",
      "Human: I'm having a halloween party. Recommend some items for me\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"I'm having a halloween party. Recommend some items for me\",\n",
       " 'chat_history': [HumanMessage(content=\"I'm having a halloween party. Recommend some items for me\"),\n",
       "  AIMessage(content=\"For your Halloween party, I recommend the following items:\\n\\n1. Spooky Cookies: These Halloween-themed cookies will be a hit with your guests. They are not only delicious but also add a festive touch to your party.\\n\\n2. Haunted chips: These scary and festive treats are perfect for the fall season. They will add a spooky element to your party and satisfy your guests' snack cravings.\\n\\n3. Keebler cookies: These assorted cookies are a crowd-pleaser. With a variety of flavors, they are sure to please everyone at your party.\\n\\n4. Chips Ahoy cookies: These classic chocolate chip cookies are always a hit. They are a timeless treat that your guests will enjoy.\\n\\nWith these snacks, you'll have a great variety of treats for your Halloween party. Enjoy your spooky celebration!\")],\n",
       " 'answer': \"For your Halloween party, I recommend the following items:\\n\\n1. Spooky Cookies: These Halloween-themed cookies will be a hit with your guests. They are not only delicious but also add a festive touch to your party.\\n\\n2. Haunted chips: These scary and festive treats are perfect for the fall season. They will add a spooky element to your party and satisfy your guests' snack cravings.\\n\\n3. Keebler cookies: These assorted cookies are a crowd-pleaser. With a variety of flavors, they are sure to please everyone at your party.\\n\\n4. Chips Ahoy cookies: These classic chocolate chip cookies are always a hit. They are a timeless treat that your guests will enjoy.\\n\\nWith these snacks, you'll have a great variety of treats for your Halloween party. Enjoy your spooky celebration!\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.clear()\n",
    "qa({\"question\": \"I'm having a halloween party. Recommend some items for me\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e4ec8",
   "metadata": {
    "id": "2f9e4ec8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
